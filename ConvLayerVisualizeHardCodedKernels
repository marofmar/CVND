'''
Convolutional Layer visualize with hard-coded kernels
'''

import cv2 
import matplotlib.pyplot as plt 

img_path = './img.jpg'
bgr_img = cv2.imread(img_path) 
gray_img =cv2.cvtColor(bgr_img, cv2.COLOR_BGR2GRAY) 
gray_img = gray_img.astype('float32')/255 # normalize 

# Define and visualize filters 
import numpy as np 
filter_vals = np.array([[-1,-1,1,1],
						[-1,-1,1,1],
						[-1,-1,1,1],
						[-1,-1,1,1]])

filter_1 = filter_vals 
filter_2 = -filter_vals
filter_3 = filter_vals.T 
filter_4 = -filter_3 

filters = np.array([filter_1, filter_2, filter_3, filter_4]) 



#Visualize four filters 
fig = pl.figure(figsize = (10, 5)) 
for i in range(4):
	ax = fig.add_subplot(1, 4, i+1, xticks = [], yticks = []) 
	ax.imshow(filters[i], cmap = 'gray') 
	width, height = filter[i].shape 
	for x in range(width):
		for y in range(height):
			ax.annotate(str(filters[i][x][y]), xy = (y, x), horizontalalignment = 'center',
															verticalalignment = 'center',
															colot = 'white', if filters[i][x][y] < 0, else 'black') 




# Define convolutional layer 
import torch 
import torch.nn as nn 
import torch.nn.functional as F 

class Net(nn.Module):
	def __init__(self, weight):
		super(Net, self).__init__() 
		k_height, k_width = wight.shape[2:]
		self.conv = nn.Conv2d(1, 4, kernel_size = (k_height, k_widht), bias = False) 
		self.conv.weight = torch.nn.Parameter(weight) 
	def forward(self.x):
		conv_x = self.conv(x)
		activated_x = F.relu(conv_x) 
		return conv_x, activated_x





# Do it
weight = torch.from_numpy(filters).unsqueeze(1).type(torch.FloatTensor) 
model = Net(weight) 








